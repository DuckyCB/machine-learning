{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bbd55",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def displaycorr(df0):\n",
    "    corr= df0.corr()\n",
    "\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.ones_like(corr, dtype=bool)\n",
    "    for i in range(len(mask[0])):\n",
    "        for j in range(len(mask[1])):\n",
    "            if j<=i:\n",
    "                mask[i][j] = not mask[i][j]\n",
    "\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "\n",
    "\n",
    "    #if np.random.randint(10, size=1)[0]  not in (1,0):\n",
    "    #    color = 'rocket_r'\n",
    "    #    cmap = sns.color_palette(color, as_cmap=True)\n",
    "    #elif np.random.randint(2, size=1)[0]:\n",
    "    color = \"Spectral\"\n",
    "    cmap = sns.color_palette(color, as_cmap=True)\n",
    "    #else:\n",
    "     #   cmap = sns.diverging_palette(210, 110, l=80, center=\"light\", as_cmap=True)\n",
    "\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0, annot=True,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .7})\n",
    "\n",
    "display_info=False\n",
    "df=[]\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        if \".csv\" in filename:\n",
    "            df.append(pd.read_csv(f'{dirname}/{filename}'))\n",
    "features_df=df[1]\n",
    "temp_df=df[0]\n",
    "\n",
    "#detecto nulls\n",
    "if display_info:\n",
    "    features_df.info()\n",
    "    print('--Nulls--')\n",
    "    print(features_df.isna().sum())\n",
    "    print(features_df.describe().T)\n",
    "#sacar nulls    \n",
    "#ESTA MAL SACAR LOS NULLOS DE PAGO MINIMO?----------------------------------------\n",
    "aux=[]    \n",
    "id_df = pd.DataFrame(aux, columns=['CUST_ID', 'PHONE', 'CONTACTS'])\n",
    "id_df[['CUST_ID', 'PHONE', 'CONTACTS']] = temp_df['CUST_ID;PHONE;CONTACTS'].str.split(';', expand=True)\n",
    "id_df.describe().T\n",
    "    \n",
    "features_df.drop(['CUST_ID'], axis=1)\n",
    "data_frame = pd.concat([features_df.drop(['CUST_ID'], axis=1),id_df],axis=1)\n",
    "data_frame= data_frame.dropna(axis=0, subset=['MINIMUM_PAYMENTS'])\n",
    "data_frame= data_frame.dropna(axis=0, subset=['CREDIT_LIMIT'])\n",
    "data_frame.info()\n",
    "#correlacion\n",
    "displaycorr(data_frame)\n",
    "data_frame.hist(bins=30, figsize=(20, 14))\n",
    "##---------------------------DATA RREADY TO USE-----------------------  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d70a01",
   "metadata": {},
   "source": [
    "Parte 3\n",
    "Utilizando el algoritmo k-means efectúe una clusterización del dataset entregado.\n",
    "Detecte aquellos clusters relevantes para el problema, describiéndolos en términos de negocio. Debe de graficar el resultado de la clusterización, se recomienda el uso de\n",
    "PCA para bajar la dimensionalidad de los datos.\n",
    "Utilice las técnicas que considere necesarias para determinar la cantidad óptima de\n",
    "clusters, justificando claramente las decisiones tomadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a85a45",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot3d(x,y,z,colors):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import cm\n",
    "    from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    ## Matplotlib Sample Code using 2D arrays via meshgrid\n",
    "    threedee = plt.figure().gca(projection='3d')\n",
    "    threedee.scatter(x, y, z,c=colors, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',7))\n",
    "    plt.show()\n",
    "def best_K_cluster_silueta(x,a,b):\n",
    "    from sklearn.metrics import silhouette_score \n",
    "    from sklearn.cluster import KMeans\n",
    "    import matplotlib.pyplot as plt\n",
    "    sil = []\n",
    "    for k in range(a,b):\n",
    "        km=KMeans(n_clusters =k).fit(x)\n",
    "        sil.append(silhouette_score(x,km.labels_,metric='euclidean'))\n",
    "    plt.plot(range(a,b),sil,'bx-')\n",
    "    plt.title('Silueta')\n",
    "    plt.show()\n",
    "def best_K_cluster_codo(x,b):\n",
    "    from sklearn.cluster import KMeans\n",
    "    from scipy.spatial.distance import cdist\n",
    "    import matplotlib.pyplot as plt\n",
    "    cod = []\n",
    "    for k in range(1,b):\n",
    "        km=KMeans(n_clusters =k).fit(x)\n",
    "        cod.append(sum(np.min(cdist(x,km.cluster_centers_,'euclidean'),axis=1))/x.shape[0])\n",
    "    plt.plot(range(1,b),cod,'bx-')\n",
    "    plt.title('Codo')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "features_df=data_frame.copy().drop(['CUST_ID', 'PHONE', 'CONTACTS'], axis=1) # removemos contactos porque no tinen correlacion enontces queda como un vector en el pca y molesta\n",
    "features_df.head()\n",
    "\n",
    "\n",
    "pca = PCA(n_components=17)\n",
    "pca.fit(features_df)\n",
    "pca_samples = pca.transform(features_df)#veo las pocisiones reales no noramlizadas\n",
    "ps = pd.DataFrame(pca_samples)\n",
    "#displaycorr(ps)\n",
    "features_df.head()\n",
    "#plot3d(ps[0], ps[1], ps[2])\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(ps[0], ps[1], 'o', markersize=4, color='blue', label='class1')\n",
    "\n",
    "plt.xlabel('x_values')\n",
    "plt.ylabel('y_values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plot3d(-ps[0], ps[1], ps[2])\n",
    "#plot3d(ps[0], -ps[1], ps[2])\n",
    "#plot3d(-ps[0], -ps[1], ps[2])\n",
    "#plt.show()\n",
    "#best_K_cluster_silueta(features_df,2,20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e2b93",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#best_K_cluster_codo(features_df,20)\n",
    "# no normalizado                  \n",
    "                   \n",
    "algorithm = (KMeans(n_clusters =6 ,init='k-means++', n_init = 10 ,max_iter=300, \n",
    "                        tol=0.0001,  random_state= 111  , algorithm='elkan') )\n",
    "algorithm.fit(features_df)\n",
    "algorithm.labels_\n",
    "print( algorithm.cluster_centers_)\n",
    "algorithm.labels_.shape\n",
    "print(algorithm.labels_)\n",
    "plot3d(ps[0], ps[1], ps[2],algorithm.labels_)\n",
    "plt.scatter(ps[0], ps[1],\n",
    "            c=algorithm.labels_, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',7))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0de2c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#normalizado\n",
    "x = features_df.values \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "features_df_norm = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=17)\n",
    "pca.fit(features_df_norm)\n",
    "pca_samples = pca.transform(features_df_norm)\n",
    "psn = pd.DataFrame(pca_samples)\n",
    "#displaycorr(ps)e\n",
    "features_df.head()\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(psn[0], psn[1], 'o', markersize=4, color='blue', label='class1')\n",
    "\n",
    "plt.xlabel('x_values')\n",
    "plt.ylabel('y_values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "                   \n",
    "algorithmn = (KMeans(n_clusters =6 ,init='k-means++', n_init = 10 ,max_iter=300, \n",
    "                        tol=0.0001,  random_state= 111  , algorithm='elkan') )\n",
    "algorithmn.fit(features_df_norm)\n",
    "algorithmn.labels_\n",
    "print( algorithmn.cluster_centers_)\n",
    "algorithmn.labels_.shape\n",
    "print(algorithmn.labels_)\n",
    "\n",
    "plot3d(psn[0], psn[1], psn[2],algorithmn.labels_)\n",
    "\n",
    "plt.scatter(psn[0], psn[1],\n",
    "            c=algorithmn.labels_, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',7))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de98a06",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#extra \n",
    "#estas funciones demoran y son cpu consuming sobretodo la silueta\n",
    "best_K_cluster_silueta(features_df,2,20)\n",
    "best_K_cluster_silueta(features_df_norm,2,20)\n",
    "best_K_cluster_codo(features_df,20)\n",
    "best_K_cluster_codo(features_df_norm,20)\n",
    "\n",
    "#============K=2 clusters=========\n",
    "#usar 6 por le segundo maximo relativo de siluera \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ca0af",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Los clusters no son iguales\n",
    "#clusters encontrados con los datos normalizados vistos en el dataframe sin normalizar\n",
    "plt.scatter(ps[0], ps[1],\n",
    "            c=algorithmn.labels_, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',7))\n",
    "plt.xlabel('vector 1')\n",
    "plt.ylabel('vector 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e3004",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#clsuters encontrados con los datos sin normalizar vistos sobre el dataframe normalizado\n",
    "plt.scatter(psn[0], psn[1],\n",
    "            c=algorithm.labels_, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',7))\n",
    "plt.xlabel('vector 1')\n",
    "plt.ylabel('vector 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff118f9",
   "metadata": {},
   "source": [
    "Parte 4\n",
    "________________________\n",
    "\n",
    "En sus propias palabras, describa las técnicas de clustering basadas en densidad, en\n",
    "particular el algoritmo DBSCAN. Aplique DBSCAN al dataset y compare los resultados\n",
    "con los obtenidos en la parte 3.\n",
    "\n",
    "--------------------\n",
    "Al clusterizar basado en densidad losn puntos se separan en 2 tipos, los que pertenecen a una agrupacion de puntos y los puntos de 'ruido'.El primer cluster esta formado por los puntos de ruidos  mientras el resto de los clusters se definen por los puntos que estan proximos.En el otro tipo de clusterizacion los puntos de ruidos se agruparian a los clusters más cercanos y no a el ruido,ademas no estan agrupados por un centroide por lo que los clusters se ven mas 'naturales'.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd837799",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "density_clustering = DBSCAN(eps=0.3, min_samples=4).fit(features_df_norm)    #minsampoles tinee que ser mayor a uno sno cada punto es un cluster minimo\n",
    "print(density_clustering.labels_)\n",
    "plt.scatter(psn[0], psn[1],\n",
    "            c=density_clustering.labels_, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',4))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar()\n",
    "plt.show\n",
    "\n",
    "\n",
    "plot3d(psn[0], psn[1], psn[2],density_clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd6666",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(ps[0], ps[1],\n",
    "            c=density_clustering.labels_, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',4))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "print(density_clustering.labels_)\n",
    "density_clustering\n",
    "\n",
    "plot3d(ps[0], ps[1], ps[2],density_clustering.labels_)\n",
    "print(Counter(density_clustering.labels_)) #ver la cantidad de clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4499c",
   "metadata": {},
   "source": [
    "Parte 5\n",
    "Estudie y explique el método de Ward utilizado en clustering aglomerativo, en\n",
    "particular, la implementación de sklearn.\n",
    "\n",
    "El clustering aglomerativo del agrupamiento jerárquico es un método de análisis de grupos\n",
    "que agrupa los elementos desde las hojas hacia la raiz del árbol, cada observación \n",
    "comienza en su propio grupo (en las hojas del árbol), y los elementos de los grupos son \n",
    "mezclados mientras uno sube en la jerarquia añadiendo elementos que tienen un mismo \n",
    "padre en común.\n",
    "\n",
    "Un cluster aglomerativo tiene un comportamiento en el que \"el rico se vuelve más rico\", \n",
    "provocando clusters desiguales y agrupando nuevos elementos en los clusters de mayor tamaño.\n",
    "\n",
    "Especificamente el Ward, minimiza la suma cuadrada de diferencias entre todos los clusters. \n",
    "Presentando un acercamiento donde se minimiza la varianza y distancia entre los elementos, \n",
    "de cierta forma teniendo un funcionamiento similar al de k-means pero abordado con \n",
    "jerarquias aglomerativas. Por su funcionamiento, este permite tener clusters mejor \n",
    "balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c3450",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster  = AgglomerativeClustering(6,linkage='ward').fit(features_df_norm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5421e91",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(cluster.labels_)\n",
    "plt.scatter(ps[0], ps[1],\n",
    "            c=cluster.labels_, edgecolor='none', alpha=0.51,\n",
    "            cmap=plt.cm.get_cmap('Spectral',4))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "\n",
    "plot3d(ps[0], ps[1], ps[2],cluster.labels_)\n",
    "print(Counter(cluster.labels_)) #ver la cantidad de clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6ba08",
   "metadata": {},
   "source": [
    "Parte 6\n",
    "Planificando próximas etapas, el banco requiere armar un cuestionario para nuevos\n",
    "clientes, de forma de poder ofrecer el producto a usuarios de los cuales no cuenta con\n",
    "histórico transaccional. Para esto, el Departamento Comercial solicita que se\n",
    "construya, a partir del análisis de datos, el listado de preguntas y un modelo predictivo\n",
    "que en función de las respuestas retorne la propensión de compra de los productos.\n",
    "En caso de que entienda que no es posible cumplir con alguno de estos\n",
    "requerimientos, documente los motivos que lo llevaron a tomar esa conclusión.\n",
    "\n",
    "Tomariamos la decisiones bandasnos en un cuestionarios booleano donde cada si sumaria puntos ,a la hora ofrecer los servicios nos fijariamos si puntaje del cuestionario es mayor a 60% de #preguntas\n",
    "\n",
    "Las preguntas serian del estilo\n",
    "\n",
    "Va a depositar mas de X dolares en su cuenta de banco? (x siendo 0.6 del  maximo actual de balance)\n",
    "Cuenta con un ingreso liquido superior a Y dolares por mes?(especular el PRC_FULL_PAYMENT)\n",
    "Frecuenta sitios de compra como Amazon, MercadoLibre ,TiendaMia?()\n",
    "Viaja al menos una vez cada 3 meses?(porpenso a nnececitar una tarjeta internacional)\n",
    "Suele realizar compras en productos no esenciales con un valor superior a Z dolares?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104588b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "############# no correr### 128 plots\n",
    "for i in range(17):\n",
    "    for j in range(17):\n",
    "        if j>i and i>0:\n",
    "            plot3d(psn[i], psn[j],psn[0],algorithmn.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c3f32",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#estudipo de a quiens ofrecerles los servicios\n",
    "data = algorithmn.cluster_centers_\n",
    "columns=features_df.columns\n",
    "final_df = pd.DataFrame(data,  columns=columns)\n",
    "final_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc41328",
   "metadata": {},
   "source": [
    "Parte 7\n",
    "Ensaye una discusión general del trabajo realizado, haciendo los comentarios y\n",
    "recomendaciones que considere necesarias.\n",
    "\n",
    "Outliners: la eliminzacion de outliner no la vimos necesaria, nos guiamos por el poensamiento de 'porque una persona tenga mucha o poca plata no significa que yo como banco no voy a ofrecerle mi servicios',este pensamiento está condicionado por idea de que como banco no pierdo nada ofreciendo a todos mis clientes un servicio. \n",
    "\n",
    "Los nullos decidimos eliminarlos del dataset porque no sabesmos si hacen referenica a ser 0 o a que flata informcaion por lo que lo tomamos como que falta.\n",
    "\n",
    "A la hora de elegir la cantidad de clusters para el kmeans al principio usamos 2 pero decidimos que estos no eran representativos para  los \"tipos\" de clientes que tiene el banco por lo que usamos una segunda opcion de 6 clusters.\n",
    "\n",
    "Otro dilema fue el de normalizar los datos o no(para el kmeans) asi que probamos los 2 caminos y comparamso que no era lo mismo. Concluimos que ningun feature era sustancialmente más importante sobre los otros al decidir para los 2 sevicios por lo que usamos los datos normalizados(en el caso de cluster por densidad era necesarioq ue fuera normalizado)\n",
    "Para la decision de a quienes ofrecer lso servicios usamos los centroides de los clusters normalizados.Los centroides representarian un cliente tipo , entonces el problema se reduce a elegir si ofrecer servicios a 6 'clientes' o no.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Despues de normalizar el dataset notamos que y ver su representacion con PCA (en los valores mas importantes(con mayor valor propio asociado)) vimos que los puntos estaban bastantes concentrados, asi que supusimos que los algoritmos de clustrizacion por densidad iban a ser poco efectivos(luego se visualizamos esto al usar DBSCAN)   \n",
    "\n",
    "\n",
    "Tarjeta Platinum\n",
    "-----------------------\n",
    "En primera instancia a los clientes del cluster 5 y 3 no seria recomendable ofrecer este servicio , por el bajo balance en sus cuentas(sobre todo en el 3) y (en el 5) por el poco uso de esta(BALANCE_FREQUENCY  PURCHASES PURCHASES_FREQUENCY,ONEOFF_PURCHASES_FREQUENCY,CASH_ADVANCE_FREQUENCY\tCASH_ADVANCE_TRX),\n",
    "Los clientes de los clusters 4 y 1 son los seria mas benefectorio ofrecer el servicio\n",
    "La decision de ofrecercelo a los clientes del cluster 1 y 2 es conflictiva ya que tiene  una baja freceuncia de pago y porcentaje de pago. \n",
    "Internet Global\n",
    "-----------------------\n",
    "Posibles candidatos para este servicio serian el 1,3 y 4 debido a su alto PURCHASES_INSTALLMENTS_FREQUENCY y  INSTALLMENTS_PURCHASES sobre todo 1 y 4 por su alto BALANCE\n",
    "Mientras los clientes del cluster 2 y 5 tiene  bajo INSTALLMENTS_PURCHASE y PURCHASES_FREQUENCY\t\n",
    "El 0 es controvercial tiene alto PURCHASES_FREQUENCY pero bajo  INSTALLMENTS_PURCHASE , BALANCE medio  alto ONEOFF_PURCHASES_FREQUENCY, es un estereotipo de cliente promedio en varios features, personalmente le ofreceriamos ambos de  servicios"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}